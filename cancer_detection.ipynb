{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cancer_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dB0xqiAI5vTc",
        "DVo3883Md4nb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veI-sWPvsnQV"
      },
      "source": [
        "# CANCER DETECTION IN DERMOSCOPIC IMAGES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uy3_z1ttMBn"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "[According to the World Health Organization](https://www.who.int/news-room/fact-sheets/detail/cancer), skin cancer is the fifth most common type of cancer in the world, with 1.2 million new cases diagnosed in 2020. \n",
        "\n",
        "Thanks to the pattern recognition capabilities of Convolutional Neural Networks, melanoma can be early detected by visually analyzing the characteristic of a skin mole. In this notebook we propose a cancer detection algorithm based on some of the most typical CNN arquitectures (Resnet, Inception, MobileNet, DenseNet and a from scrath network). \n",
        "\n",
        "We used ISIC DB 2018 dataset to evaluate the experiments. A highly imbalanced dataset containing 2750 dermoscopic images, publicly available here: https://challenge.isic-archive.com/data\n",
        "\n",
        "The dataset was stored in my personal Google Drive account.\n",
        "\n",
        "*This code was developed from scratch out of personal curiosity, so there may be some minor errors and hard-coding*. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2vCuzk-Y_L"
      },
      "source": [
        "## Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB0xqiAI5vTc"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu5hdxWg5ww1"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import collections\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.autograd import Function\n",
        "from torch.autograd import Variable\n",
        "import torch.cuda.amp as amp\n",
        "\n",
        "import statistics as stats\n",
        "import random\n",
        "import scipy.io\n",
        "from PIL import Image\n",
        "import cv2 as cv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K5HwiQWs1Fv"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fafu3A7Es34U",
        "outputId": "c5f764a5-eb80-4f55-b5c2-e0516a6e71d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/') #Mount Drive "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7G6rT6hs-gJ"
      },
      "source": [
        "#Use GPU if available. (Runtime -> Change runtime type -> GPU)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvD4J_MXi_-9",
        "outputId": "ef6a924a-67b9-48cf-96bd-5416f266423c"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logdir = \"runs/exp1\"\n",
        "writer = SummaryWriter(log_dir=logdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOb0uW0NxpKp"
      },
      "source": [
        "### Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvVbpJBWxr1r"
      },
      "source": [
        "def lesion(mask):\n",
        "  \"\"\"\n",
        "    This function generates a binary mask that separates background pixels (healthy skin) and the lesion.\n",
        "    The mask is used to eliminate the maximum amount of background pixels when reading an image from the dataset.\n",
        "  \n",
        "      input: mask(h,w), indices[0,6]: Bg, Others, Cysts...\n",
        "      output: mask'(h,w), indices[0,1]: Bg, Fg \n",
        "  \"\"\"\n",
        "\n",
        "  new = np.zeros(mask.shape)\n",
        "  new[(mask==0)] = 0 \n",
        "  new[(mask==1)] = 1 \n",
        "  new[(mask==2)] = 1  \n",
        "  new[(mask==3)] = 1  \n",
        "  new[(mask==4)] = 1 \n",
        "  new[(mask==5)] = 1 \n",
        "  new[(mask==6)] = 1 \n",
        "\n",
        "  return new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW4t7w_xxt7G"
      },
      "source": [
        "def get_segment_crop(img,tol=0, mask=None):\n",
        "  \"\"\"\n",
        "  This function crops and image given a background-foreground binary mask. \n",
        "    inputs: image [c, h, w]\n",
        "             mask [1, h, w]\n",
        "    output: image [c, h', w'], where h'w' < hw        \n",
        "  \"\"\"\n",
        "  if mask is None:\n",
        "    mask = img > tol\n",
        "  \n",
        "  return img[np.ix_(mask.any(1), mask.any(0))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9hRmJLGvXBv"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dfo9oYZvYLk"
      },
      "source": [
        "#ISIC DB mean/std \n",
        "mean = [0.1769, 0.1479, 0.1367]\n",
        "std = [0.0352, 0.0378, 0.0417]\n",
        "\n",
        "#These operations are applied to the training set. \n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Resize([300,]),\n",
        "     transforms.RandomCrop(size=(300)),\n",
        "     #transforms.RandomRotation(90),\n",
        "     transforms.RandomVerticalFlip(p=0.5), \n",
        "     transforms.RandomHorizontalFlip(p=0.5)\n",
        "    ])\n",
        "\n",
        "#These operations are applied to the validation and test set to evaluate the model.\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Resize([300,], interpolation=transforms.InterpolationMode.NEAREST),\n",
        "     transforms.RandomCrop(size=300)\n",
        "    ])\n",
        "\n",
        "#Data augmentation in the RGB channels\n",
        "data_aug = transforms.Compose(\n",
        "    [transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=mean, std=std),\n",
        "     transforms.ToPILImage()\n",
        "     \n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fswNX4gTucaQ"
      },
      "source": [
        "### Dataset and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDY3-MZmuddq"
      },
      "source": [
        "class db_isic_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, idx, transform=None, data_aug=None, subset='train'):\n",
        "    self.root = root\n",
        "    self.idx = idx\n",
        "    self.db = idx['db']\n",
        "    self.transform = transform\n",
        "    self.data_aug = data_aug\n",
        "    self.subset = subset\n",
        "    \n",
        "    subset_idx = []\n",
        "    if(self.subset == 'train'):\n",
        "      subset_idx = np.where(self.db['set']==1) #Train\n",
        "    elif(self.subset == 'val'):\n",
        "      subset_idx = np.where(self.db['set']==2) #Val \n",
        "    elif(self.subset == 'test'):\n",
        "      subset_idx = np.where(self.db['set']==3) #Test\n",
        "\n",
        "\n",
        "    self.db = self.db[subset_idx]\n",
        "    self.imPath, self.gt, self.dlabel = self.db['imPath'], self.db['gt'], self.db['dlabel']\n",
        "    self.imagePath = ['']*len(self.imPath)\n",
        "    self.gtPath = ['']*len(self.imPath)\n",
        "   \n",
        "  def __getitem__(self, index):\n",
        "    imagePath = os.path.join(self.root, self.imPath[index][0])\n",
        "    gtPath = os.path.join(self.root, self.gt[index][0])\n",
        "\n",
        "    image_t = Image.open(imagePath)\n",
        "\n",
        "    mask = scipy.io.loadmat(gtPath)['smgt'] #Segmentation ground truth mask\n",
        "    foreground = lesion(mask) #Get foreground mask\n",
        "\n",
        "    image_t = get_segment_crop(np.asarray(image_t), mask=foreground) #Eliminate background pixels\n",
        "\n",
        "    dlabel = self.dlabel[index][0] #Diagnostic label. '0': non-cancer, '1': cancer\n",
        "    dlabel= torch.from_numpy(dlabel)\n",
        "    dlabel = np.clip(dlabel, 0, 1)\n",
        "    dlabel = dlabel.float()\n",
        "    \n",
        "    if self.data_aug: #Data augmentation\n",
        "      image_t = self.data_aug(image_t)\n",
        "      \n",
        "    if self.transform: #Geometrical transformations. \n",
        "      image_t = self.transform(image_t)\n",
        "\n",
        "    return image_t, dlabel\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O-cQvixupz1"
      },
      "source": [
        "ROOT = \"/content/drive/My Drive/db_isic/\"\n",
        "path = \"/content/drive/My Drive/db_isic/idx/isic_2017.mat\"\n",
        "idx = scipy.io.loadmat(path)\n",
        "\n",
        "trainset = db_isic_Dataset(root=ROOT, idx=idx, transform=transform, subset='train')\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "validationset = db_isic_Dataset(root=ROOT, idx=idx, transform=transform, subset='val')\n",
        "validationloader = torch.utils.data.DataLoader(validationset, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "data_loaders = {\"train\": trainloader, \"val\": validationloader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIVXbk9Szkno"
      },
      "source": [
        "### Arquitectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlqvHfjtZVUS"
      },
      "source": [
        "#### Resnet101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjUbR9iUz-2u"
      },
      "source": [
        "def resnet101(num_classes=1):\n",
        "  model = models.resnet101(pretrained=True)\n",
        "  model.fc = nn.Sequential(\n",
        "      nn.Linear(2048, num_classes),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbL-_ZjOZXVM"
      },
      "source": [
        "#### Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4xB5DqkY3lw"
      },
      "source": [
        "def resnet18(num_classes=1):\n",
        "  model = models.resnet18(pretrained=True)\n",
        "\n",
        "  model.fc = nn.Sequential(\n",
        "      nn.Linear(512, num_classes),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK2T0KjLaL3R"
      },
      "source": [
        "#### Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv-dt5LlZaA-"
      },
      "source": [
        "def inceptionv3(num_classes=1):\n",
        "  model = models.inception_v3(pretrained=True)\n",
        "\n",
        "  model.fc = nn.Sequential(\n",
        "      nn.Linear(2048, num_classes),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return model #Forward function returns the actual output in output[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc6Nu9E3a6vr"
      },
      "source": [
        "#### Mobilenet v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUsq67t0aOG5"
      },
      "source": [
        "def mobilenet(num_classes=1):\n",
        "  model = models.mobilenet_v3_large(pretrained=True)\n",
        "\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Linear(960, num_classes),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEScXAcFbcih"
      },
      "source": [
        "#### Densenet169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Nl6rHPa_RW"
      },
      "source": [
        "def densenet169(num_classes=1):\n",
        "  model = models.densenet169(pretrained=True)\n",
        "\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Linear(1664, num_classes),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVo3883Md4nb"
      },
      "source": [
        "#### From scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diXtxX_zd6io"
      },
      "source": [
        "class scratch(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):  \n",
        "        super().__init__()\n",
        "        input_channels = 3\n",
        "        output_channels = 1\n",
        "        \n",
        "        #DOWNSAMPLING ---------------------------------------------------------\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_channels, 64, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU()       \n",
        "        )\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(128, 128, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU()      \n",
        "        )\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(128, 256, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(256, 256, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(256, 512, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(512, 1024, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(1024, 1024, kernel_size=(3,3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.BatchNorm2d(1024),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, output_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.layer5(x) \n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    print(x.shape)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XijmsAy80Kgk"
      },
      "source": [
        "#Debug\n",
        "model = scratch()\n",
        "\n",
        "hw = 300\n",
        "input  = torch.rand((2,3,hw,hw)) #Generate random 3-channel tensor (input image)\n",
        "\n",
        "out = model(input)\n",
        "\n",
        "print(out.shape) #(2, 1)\n",
        "print(out) #Scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUH8kimfcA3w"
      },
      "source": [
        "def model_selector(model=\"resnet101\"):\n",
        "  if(model==\"resnet101\"):\n",
        "    return resnet101()\n",
        "  elif(model==\"resnet18\"):\n",
        "    return resnet18()\n",
        "  elif(model==\"inception\"):\n",
        "    return inception()\n",
        "  elif(model==\"mobilenet\"):\n",
        "    return mobilenet()\n",
        "  elif(model==\"densenet\"):\n",
        "    return densenet169()\n",
        "  elif(model==\"scratch\"):\n",
        "    return scratch()  \n",
        "  else:\n",
        "    print(\"The model you selected is not available.\")\n",
        "    print(\"...Resnet101 is selected.\") \n",
        "    return resnet101()         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUiYFMRnEWTt"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "*To be completed...*\n",
        "\n",
        "NOTE: the idea is to penalize False Negatives as they have a major impact than False Positives. **We do not want to miss detecting cancer**. We can use Tversky Loss to balance the contribution of FP and FN.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TV-9wB5EZPb"
      },
      "source": [
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1, alpha=0.7, beta=0.3):\n",
        "\t\"\"\"\n",
        "        inputs: raw output predictions (without activation). Shape: [batch, num_classes, h, w]\n",
        "        targets: ground truth labels (one-hot encoded). Shape: [batch, num_classes, h, w]\n",
        "\talpha: False Positives weighting coefficient\n",
        "\tbeta: False Negatives weighting coefficient\n",
        "        \"\"\"\n",
        "        \n",
        "        inputs = torch.nn.functional.softmax(inputs, dim=1)\n",
        "\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.contiguous().view(-1)\n",
        "        targets = targets.contiguous().view(-1)\n",
        "        \n",
        "        #True Positives, False Positives & False Negatives\n",
        "        TP = (inputs * targets).sum()    \n",
        "        FP = ((1-targets) * inputs).sum()\n",
        "        FN = (targets * (1-inputs)).sum()\n",
        "\n",
        "                \n",
        "\n",
        "        Tversky = (2*TP + smooth) / (2*TP + alpha*FP + beta*FN + smooth)  \n",
        "\n",
        "   \n",
        "        return 1 - Tversky"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0EhbIVS0xd9"
      },
      "source": [
        "### Model and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2w0rhU0y1t"
      },
      "source": [
        "#Arquitectures available: \"resnet101\", \"resnet18\", \"inception\", \"mobilenet\", \"densenet\", \"scratch\"\n",
        "arquitecture = \"resnet101\"\n",
        "model = model_selector(model=arquitecture)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion =  nn.BCELoss() #Binary Cross Entropy*. *We need to calculate the probabilities a priori of cancer vs non-cancer.\n",
        "#criterion = nn.MSELoss() #Mean Squared Error\n",
        "#criterion = TverskyLoss() #Tversky Loss\n",
        "\n",
        "#Layer parameters for Resnet models*. \n",
        "p1 = [p for p in model.layer2.parameters() if p.requires_grad]\n",
        "p2 = [p for p in model.layer3.parameters() if p.requires_grad]\n",
        "p3 = [p for p in model.layer4.parameters() if p.requires_grad]\n",
        "\n",
        "\n",
        "#Stochastic Gradient Descend with momentum. \n",
        "optimizer = optim.SGD([{'params': p1, 'lr': 1e-7},   \n",
        "                       {'params': p2, 'lr': 1e-6},\n",
        "                       {'params': p3, 'lr': 1e-4}\n",
        "                        ], lr=1e-3 , momentum=0.999, nesterov=True)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "num_epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSxkoN8c2IJz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWc2Qt52JMn"
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/Checkpoints/diagnostic.tar\" #Load and save model each epoch in a .tar file.\n",
        "\n",
        "saveCheckpoint = False #Saves the model\n",
        "loadCheckpoint = False #Loads the model\n",
        "#---------------------------------------------------------------------------------\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "\n",
        "if(loadCheckpoint):\n",
        "  print(\"Loading checkpoint... | Path: \", checkpoint_path)\n",
        "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    if(epoch > 0):  \n",
        "      if(saveCheckpoint): #Save model\n",
        "          print(\"Saving checkpoint... | epoch: \", epoch, \"| Path: \", checkpoint_path)\n",
        "          torch.save({'model_state_dict': model.state_dict(),  \n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'scheduler_state': scheduler.state_dict()},\n",
        "                      checkpoint_path)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "\n",
        "        if phase == 'train':\n",
        "            model.train()  # Set model to training mode\n",
        "            print(\"Epoch: \", epoch, \"| Training phase |\")\n",
        "        else:\n",
        "            model.eval()  # Set model to evaluate mode\n",
        "            model.apply(bn_eval)\n",
        "            print(\"Epoch: \", epoch, \"| Validation phase |\")\n",
        "\n",
        "        for i, data in enumerate(data_loaders[phase],0):\n",
        "          inputs, labels = data  \n",
        "          #labels = labels.long() \n",
        "                  \n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          #Predict output probabilities\n",
        "          y_score = model(inputs)          \n",
        "\n",
        "          #Calculate Loss\n",
        "          loss = criterion(y_score, labels)\n",
        "          \n",
        "          if phase == 'train':            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward() #Backpropagation\n",
        "            optimizer.step()  \n",
        "            scheduler.step() #Sch step\n",
        "            train_loss.append(loss.item())\n",
        "            writer.add_scalar(\"Loss/train\", loss.item(), i) #Tensorboard\n",
        "\n",
        "\n",
        "          if phase == 'val':\n",
        "            validation_loss.append(loss.item())\n",
        "            writer.add_scalar(\"Loss/val\", loss.item(), i) #Tensorboard\n",
        "\n",
        "\n",
        "          #if(i%5 ==0):\n",
        "          #  print(\"Scores: \", y_score)\n",
        "          #  print(\"Labels: \", labels)\n",
        "          \n",
        "writer.flush()\n",
        " \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MT8UofKhfqq"
      },
      "source": [
        "## Launch Tensorboard\n",
        "\n",
        "*It won't open if Third-party cookies are blocked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlLCdsFmjMpH"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsAT6SmbstaC"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}